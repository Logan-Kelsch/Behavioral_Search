{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41c4ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transforms as transforms\n",
    "import population as population\n",
    "import optimize as optimize\n",
    "import utility as utility\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import visualization as visualization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import evaluation as evaluation\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"../../data/ES15.csv\")\n",
    "x_raw = data.values\n",
    "\n",
    "#x_raw, x_ind = train_test_split(x_raw_presplit, test_size=0.1, shuffle=False)\n",
    "\n",
    "dirpath = utility.fetch_new_run_dirpath()\n",
    "\n",
    "\n",
    "\n",
    "pop = population.generate_random_forest(100, 12)\n",
    "\n",
    "np.seterr(all='ignore')\n",
    "best_forest, best_scores, best_overtime = optimize.optimize_constants(\n",
    "    pop, x_raw, sthresh_q=.1, run_dir=dirpath, max_iter=2, vizout=False\n",
    ")\n",
    "\n",
    "img = visualization.visualize_tree(best_forest[best_scores.index(min(best_scores))], run_dir=dirpath, vizout=True)\n",
    "best_forest , best_scores = population.extract_n_best_trees(best_forest, best_scores, -1, run_dir=dirpath, vizout=True)\n",
    "\n",
    "\n",
    "ynew = np.roll(x_raw[:, 3], shift=-1)\n",
    "y_ = np.log(ynew / x_raw[:, 3])\n",
    "#np.random.shuffle(y_)\n",
    "\n",
    "\n",
    "x_ = transforms.forest2features(\n",
    "    population=best_forest,\n",
    "    x_raw=x_raw\n",
    ")\n",
    "\n",
    "#using time column (never utilized) as noise column\n",
    "x_raw[:, 0] = 1\n",
    "noise = np.random.rand(x_raw.shape[0], 1)\n",
    "\n",
    "x_ = np.hstack([x_, noise])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_, y_, test_size=0.3, shuffle=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = evaluation.standard_NN_construction(X_train, y_train, verbose=1)\n",
    "evaluation.standard_LM_evaluation(X_train, X_test, y_train, y_test, model, dirpath, vizout=True, show=True)\n",
    "#evaluation.standard_LM_evaluation(X_train, xind_, y_train, yind_, model, dirpath, vizout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0f5088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transforms as transforms\n",
    "import population as population\n",
    "import optimize as optimize\n",
    "import utility as utility\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import visualization as visualization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import evaluation as evaluation\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"../../data/ES15.csv\")\n",
    "x_raw = data.values\n",
    "\n",
    "#x_raw, x_ind = train_test_split(x_raw_presplit, test_size=0.1, shuffle=False)\n",
    "\n",
    "dirpath = utility.fetch_new_run_dirpath()\n",
    "\n",
    "\n",
    "\n",
    "pop = population.generate_random_forest(200, 12)\n",
    "\n",
    "np.seterr(all='ignore')\n",
    "best_forest, best_scores, best_overtime = optimize.optimize_constants(\n",
    "    pop, x_raw, sthresh_q=.1, run_dir=dirpath, max_iter=-1, vizout=True\n",
    ")\n",
    "\n",
    "img = visualization.visualize_tree(best_forest[best_scores.index(min(best_scores))], run_dir=dirpath, vizout=True)\n",
    "best_forest , best_scores = population.extract_n_best_trees(best_forest, best_scores, 10, run_dir=dirpath, vizout=True)\n",
    "\n",
    "\n",
    "ynew = np.roll(x_raw[:, 3], shift=-1)\n",
    "y_ = np.log(ynew / x_raw[:, 3])\n",
    "#np.random.shuffle(y_)\n",
    "\n",
    "\n",
    "x_ = transforms.forest2features(\n",
    "    population=best_forest,\n",
    "    x_raw=x_raw\n",
    ")\n",
    "\n",
    "\n",
    "#noise = np.random.rand(x_raw.shape[0], 1)\n",
    "#x_ = np.hstack([x_, noise])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_, y_, test_size=0.3, shuffle=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b669a6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "def standard_NN_construction(X_train, y_train, epochs=250, verbose=0):\n",
    "    \n",
    "\n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.65, \n",
    "        patience=3, \n",
    "        min_lr=1e-6\n",
    "    )\n",
    "    early_stopping = EarlyStopping(monitor='loss', patience=25, mode='min', restore_best_weights=True)\n",
    "\n",
    "    opt  = tf.keras.optimizers.Adam()\n",
    "    opt2 = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "    def build_model():\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Input(shape=(X_train.shape[1],)),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),  \n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),       \n",
    "            tf.keras.layers.Dense(1, activation='linear')  # Output layer for regression\n",
    "        ])\n",
    "        \n",
    "        rmse='root_mean_squared_error'\n",
    "\n",
    "        model.compile(optimizer=opt2, loss='mse', metrics=['R2Score'])\n",
    "        return model\n",
    "\n",
    "    with tf.device('/GPU:0'):\n",
    "        model = build_model()\n",
    "        history = model.fit(X_train, y_train, epochs=epochs, batch_size=512, \\\n",
    "                        validation_split=0.2, verbose=verbose, shuffle=True, callbacks=[reduce_lr, early_stopping])\n",
    "        \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4f9391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import reproduction\n",
    "best_forest = reproduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca194cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transforms, evaluation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv(\"../../data/ES15.csv\")\n",
    "x_raw = data.values\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ynew = np.roll(x_raw[:, 3], shift=-1)\n",
    "y_ = np.log(ynew / x_raw[:, 3])\n",
    "#np.random.shuffle(y_)\n",
    "\n",
    "import serialization\n",
    "\n",
    "best_forest = serialization.load_forest(where='../../runs/run_5/best.4st')\n",
    "\n",
    "x_ = transforms.forest2features(\n",
    "    population=best_forest,\n",
    "    x_raw=x_raw\n",
    ")\n",
    "\n",
    "\n",
    "#noise = np.random.rand(x_raw.shape[0], 1)\n",
    "#x_ = np.hstack([x_, noise])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_, y_, test_size=0.3, shuffle=True, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56315764",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = evaluation.standard_LM_construction(X_train, y_train)\n",
    "evaluation.standard_LM_evaluation(X_train, X_test, y_train, y_test, model, '', vizout=False, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd1a117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualization, serialization, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv(\"../../data/ES15_ext.csv\")\n",
    "x_raw = data.values\n",
    "\n",
    "best_trees = []\n",
    "\n",
    "for i in range(34, 124):\n",
    "    print('run',i)\n",
    "    where =str(i)\n",
    "\n",
    "    try:\n",
    "        forest = \tserialization.load_forest(\twhere=str('../../runs/run_'+where+'/best.4st'))\n",
    "        path_scrs = serialization.load_deeplist(where=str('../../runs/run_'+where+'/path_pscr.hstry'))\n",
    "\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "    best_trees.append(forest[0])\n",
    "\n",
    "'''    print(path_scrs[0][-1])\n",
    "    art_thresh, ln_plratio = path_scrs[0][-1][0], path_scrs[0][-1][1]\n",
    "    import evaluation\n",
    "\n",
    "    pl_arr = evaluation.generate_pl_atrplr(x_raw, art_thresh, ln_plratio)\n",
    "    x_ = transforms.forest2features(\n",
    "        population=forest,\n",
    "        x_raw=x_raw\n",
    "    )\n",
    "    bestpls, bestsums, bestthresh = evaluation.evaluate_tree_atrplr_pl(x_, pl_arr)\n",
    "    #fig, ax = visualization.visualize_cumulative_first_feature_pl(best_pls=bestpls)\n",
    "\n",
    "    from sklearn.metrics import precision_score\n",
    "\n",
    "    if('>' in bestthresh[0]):\n",
    "\n",
    "        preds = x_[:, 0] >0\n",
    "    else:\n",
    "        preds = x_[:, 0] <0\n",
    "    trues = evaluation.generate_solarr_atrplr(x_raw, art_thresh, ln_plratio)\n",
    "    idx = ~np.isnan(trues)\n",
    "\n",
    "    best_trees.append(preds)\n",
    "\n",
    "    ps = precision_score(trues[idx], preds[idx])\n",
    "    #print('precision: ',ps)\n",
    "    R = float(np.exp(ln_plratio))\n",
    "    print('EV: ', (R * ps - ( 1 - ps )))\n",
    "    #plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65685c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path as path\n",
    "serialization.save_forest(best_trees, name='allruns.4st',dirpath=path.cwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83d2730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualization, serialization, transforms, evaluation\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv(\"../../data/ES15_ext.csv\")\n",
    "x_raw = data.values\n",
    "from pathlib import Path as path\n",
    "best_trees = serialization.load_deeplist(where='best.votes')\n",
    "xall = np.asarray(best_trees).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0957ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xall = np.asarray(best_trees).T\n",
    "xall.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bc1308",
   "metadata": {},
   "outputs": [],
   "source": [
    "serialization.save_deeplist(best_trees, name='best_ext.votes', dirpath=path.cwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6195b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c3eed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import serialization\n",
    "data = serialization.load_deeplist(where='../../runs/run_132/ensemble.data')\n",
    "e_forest = data[0]\n",
    "e_params = data[1]\n",
    "e_freqs = data[2]\n",
    "e_EVs = data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a26e6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_freqs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d40752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transforms\n",
    "import evaluation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"../../data/ES15.csv\")\n",
    "x_raw = data.values\n",
    "data_ext = pd.read_csv(\"../../data/ES15_ext.csv\")\n",
    "x_raw_ext = data_ext.values\n",
    "\n",
    "xall = transforms.forest2features(e_forest, x_raw)\n",
    "xall_ext = transforms.forest2features(e_forest, x_raw_ext)\n",
    "\n",
    "R = np.exp(np.mean(e_params[1]))\n",
    "r = np.mean(e_params[0])\n",
    "\n",
    "\n",
    "ytrue = evaluation.generate_solarr_atrplr(x_raw, r, np.log(R))\n",
    "idx = ~np.isnan(ytrue)\n",
    "ytrue = ytrue[idx]\n",
    "xall = xall[idx]\n",
    "\n",
    "yext = evaluation.generate_solarr_atrplr(x_raw_ext, r, np.log(R))\n",
    "idx_ext = ~np.isnan(yext)\n",
    "yext = yext[idx_ext]\n",
    "xall_ext = xall_ext[idx_ext]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e64eb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def _ev_from_counts(tp, fp, R: float) -> float:\n",
    "    k = tp + fp\n",
    "    if k == 0:\n",
    "        return -1.0  # no predicted positives -> EV from precision=0 → -1\n",
    "    ps = tp / k\n",
    "    return R * ps - (1 - ps)\n",
    "\n",
    "def _perm_pvalue_ev(y_true, y_pred, R: float, n_perm=5000, seed=None):\n",
    "    \"\"\"\n",
    "    One-sided Monte Carlo p-value for EV: P(EV_perm >= EV_actual).\n",
    "    Keep predictions fixed; shuffle labels.\n",
    "    \"\"\"\n",
    "    y = np.asarray(y_true).astype(int)\n",
    "    yhat = np.asarray(y_pred).astype(int)\n",
    "    mask = ~np.isnan(y)\n",
    "    y = y[mask]; yhat = yhat[mask]\n",
    "\n",
    "    mpos = (yhat == 1)\n",
    "    tp_actual = int((y[mpos] == 1).sum())\n",
    "    fp_actual = int((y[mpos] == 0).sum())\n",
    "    ev_actual = _ev_from_counts(tp_actual, fp_actual, R)\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    ge = 0\n",
    "    for _ in range(n_perm):\n",
    "        y_perm = rng.permutation(y)\n",
    "        tp = int((y_perm[mpos] == 1).sum())\n",
    "        fp = int((y_perm[mpos] == 0).sum())\n",
    "        ev = _ev_from_counts(tp, fp, R)\n",
    "        if ev >= ev_actual:\n",
    "            ge += 1\n",
    "    return (ge + 1.0) / (n_perm + 1.0), ev_actual\n",
    "\n",
    "# ---------- main: initial block first, then stream ----------\n",
    "def simulate_popvote_pvalues_ev_split(\n",
    "    X0, y0,\n",
    "    Xs, ys,\n",
    "    predictor,                 # callable: predictor(X_chunk, threshold)-> {0,1} ndarray\n",
    "    threshold=0.99,\n",
    "    R=2.0,                     # float OR callable(step_index, slice)-> float\n",
    "    chunk_size=1000,           # applies to the stream only\n",
    "    n_perm=5000,\n",
    "    seed=None,\n",
    "    plot=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate EV permutation p-values over time using a fixed pop-vote predictor.\n",
    "\n",
    "    Step 0: evaluate on the initial block (X0, y0).\n",
    "    Steps 1..T: evaluate on consecutive chunks of the stream (Xs, ys).\n",
    "\n",
    "    Returns dict of arrays for each step: p_values, EVs, precisions, pred_pos, prevalence, chunk_sizes, steps_idx.\n",
    "    \"\"\"\n",
    "    # to arrays\n",
    "    X0 = np.asarray(X0); y0 = np.asarray(y0)\n",
    "    Xs = np.asarray(Xs); ys = np.asarray(ys)\n",
    "\n",
    "    if X0.shape[0] != y0.shape[0]:\n",
    "        raise ValueError(\"X0 and y0 must have the same number of rows.\")\n",
    "    if Xs.shape[0] != ys.shape[0]:\n",
    "        raise ValueError(\"Xs and ys must have the same number of rows.\")\n",
    "\n",
    "    n_stream = Xs.shape[0]\n",
    "    n_stream_steps = (n_stream + chunk_size - 1) // chunk_size  # may include last partial\n",
    "    n_steps = 1 + n_stream_steps  # include initial block as step 0\n",
    "\n",
    "    p_values   = np.full(n_steps, np.nan)\n",
    "    EVs        = np.full(n_steps, np.nan)\n",
    "    precisions = np.full(n_steps, np.nan)\n",
    "    pred_pos   = np.full(n_steps, np.nan)\n",
    "    prevalence = np.full(n_steps, np.nan)\n",
    "    chunk_len  = np.full(n_steps, np.nan)\n",
    "    steps_idx  = []  # list of (is_initial, start, end)\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    def _get_R(step_idx, sl):\n",
    "        return float(R(step_idx, sl)) if callable(R) else float(R)\n",
    "\n",
    "    # ---- step 0: initial block ----\n",
    "    valid0 = ~np.isnan(y0)\n",
    "    X0v = X0[valid0]\n",
    "    y0v = y0[valid0].astype(int)\n",
    "\n",
    "    yhat0 = np.asarray(predictor(X0v, threshold)).astype(int)\n",
    "    if yhat0.shape[0] != y0v.shape[0]:\n",
    "        raise ValueError(f\"Predictor returned {yhat0.shape[0]} preds, expected {y0v.shape[0]} for initial block.\")\n",
    "\n",
    "    N0 = y0v.size\n",
    "    M0 = int((y0v == 1).sum())\n",
    "    k0 = int((yhat0 == 1).sum())\n",
    "    tp0 = int(((y0v == 1) & (yhat0 == 1)).sum())\n",
    "    fp0 = k0 - tp0\n",
    "\n",
    "    prevalence[0] = M0 / N0 if N0 > 0 else np.nan\n",
    "    precisions[0] = (tp0 / k0) if k0 > 0 else 0.0\n",
    "    EVs[0]        = _ev_from_counts(tp0, fp0, _get_R(0, slice(0, N0)))\n",
    "    pred_pos[0]   = k0\n",
    "    chunk_len[0]  = N0\n",
    "    steps_idx.append((True, 0, N0))  # initial block marker\n",
    "\n",
    "    p_values[0], _ = _perm_pvalue_ev(y0v, yhat0, _get_R(0, slice(0, N0)),\n",
    "                                     n_perm=n_perm, seed=rng.integers(0, 2**31-1))\n",
    "\n",
    "    # ---- steps 1..: stream chunks ----\n",
    "    for s_idx in range(n_stream_steps):\n",
    "        step = 1 + s_idx\n",
    "        start = s_idx * chunk_size\n",
    "        end   = min(n_stream, (s_idx + 1) * chunk_size)\n",
    "        steps_idx.append((False, start, end))\n",
    "\n",
    "        Xe = Xs[start:end]\n",
    "        ye = ys[start:end]\n",
    "\n",
    "        valid = ~np.isnan(ye)\n",
    "        Xe = Xe[valid]\n",
    "        ye = ye[valid].astype(int)\n",
    "        if Xe.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        yhat = np.asarray(predictor(Xe, threshold)).astype(int)\n",
    "        if yhat.shape[0] != ye.shape[0]:\n",
    "            raise ValueError(f\"Predictor returned {yhat.shape[0]} preds, expected {ye.shape[0]} for stream chunk {s_idx}.\")\n",
    "\n",
    "        N = ye.size\n",
    "        M = int((ye == 1).sum())\n",
    "        kpos = int((yhat == 1).sum())\n",
    "        tp = int(((ye == 1) & (yhat == 1)).sum())\n",
    "        fp = kpos - tp\n",
    "\n",
    "        prevalence[step] = M / N if N > 0 else np.nan\n",
    "        precisions[step] = (tp / kpos) if kpos > 0 else 0.0\n",
    "        EVs[step]        = _ev_from_counts(tp, fp, _get_R(step, slice(start, end)))\n",
    "        pred_pos[step]   = kpos\n",
    "        chunk_len[step]  = N\n",
    "\n",
    "        p_values[step], _ = _perm_pvalue_ev(ye, yhat, _get_R(step, slice(start, end)),\n",
    "                                            n_perm=n_perm, seed=rng.integers(0, 2**31-1))\n",
    "\n",
    "    out = {\n",
    "        \"p_values\": p_values,\n",
    "        \"EVs\": EVs,\n",
    "        \"precisions\": precisions,\n",
    "        \"pred_pos\": pred_pos,\n",
    "        \"prevalence\": prevalence,\n",
    "        \"chunk_sizes\": chunk_len,\n",
    "        \"steps_idx\": steps_idx,  # (is_initial, start, end) per step\n",
    "    }\n",
    "\n",
    "    if plot:\n",
    "        x = np.arange(n_steps)\n",
    "\n",
    "        # p-values over time\n",
    "        fig, ax = plt.subplots(figsize=(8, 4.2))\n",
    "        ax.plot(x, p_values, marker=\"o\", linewidth=1.5)\n",
    "        ax.axhline(0.05, linestyle=\"--\", linewidth=1)\n",
    "        ax.axhline(0.01, linestyle=\"--\", linewidth=1)\n",
    "        ax.set_xlabel(\"Step (0 = initial block; 1.. = stream chunks)\")\n",
    "        ax.set_ylabel(\"Permutation p-value (EV)\")\n",
    "        ax.set_title(\"EV p-values over time (pop-vote, initial + stream)\")\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        plt.tight_layout(); plt.show()\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10de63c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "\n",
    "\n",
    "m = 10\n",
    "n = 30\n",
    "EV_arr = np.empty((m, n))\n",
    "\n",
    "yffset = 10\n",
    "xffset = 0\n",
    "yscale = 10\n",
    "xscale = 10\n",
    "\n",
    "atrthr = 1\n",
    "ln_plr = 0\n",
    "for i in range(yffset,m+yffset):\n",
    "    for j in range(xffset,n+xffset):\n",
    "\n",
    "        atrthr = (i/yscale)\n",
    "        ln_plr = (j/xscale)\n",
    "\n",
    "        y_ = evaluation.generate_solarr_atrplr(x_raw, atrthr, ln_plr)\n",
    "        idx = ~np.isnan(y_)\n",
    "\n",
    "        y_ = y_[idx]\n",
    "        pvpred = evaluation.meta_bipopvote(xall[idx], threshold=0.99)\n",
    "\n",
    "        ps = precision_score(y_, pvpred)\n",
    "        #print(ps)\n",
    "\n",
    "        R = float(np.exp(ln_plr))\n",
    "        #print(atrthr, ln_plr)\n",
    "        EV = (R * ps - ( 1 - ps ))\n",
    "        #print('EV: ', (R * ps - ( 1 - ps )))\n",
    "        EV_arr[i-yffset, j-xffset] = EV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a403ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap, TwoSlopeNorm\n",
    "import matplotlib.ticker as mtick\n",
    "xscale, yscale = 10, 10\n",
    "def plot_heatmap(\n",
    "    data: np.ndarray,\n",
    "    xlabel: str = 'Exit Ratio',\n",
    "    ylabel: str = 'Risk Coef',\n",
    "    title: str = \"Expected Value Topology\\nof Solution Models' Consensus\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot a heatmap of a 2D array where:\n",
    "      -  0 maps to white (ground) whenever 0 is in range\n",
    "      - values <  0 map to red shades\n",
    "      - values >  0 map to green shades\n",
    "    Automatically handles cases where data is only ≥0 or only ≤0.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.ndarray, shape (M, N)\n",
    "    xlabel : str, optional\n",
    "    ylabel : str, optional\n",
    "    title : str, optional\n",
    "    \"\"\"\n",
    "    data_min = np.nanmin(data)\n",
    "    data_max = np.nanmax(data)\n",
    "\n",
    "    # Case 1: data spans negative and positive\n",
    "    if data_min < 0 < data_max:\n",
    "        cmap = LinearSegmentedColormap.from_list(\"r_w_g\", [\"red\", \"white\", \"green\"])\n",
    "        norm = TwoSlopeNorm(vmin=data_min, vcenter=0, vmax=data_max)\n",
    "    # Case 2: data all non-negative → white to green\n",
    "    elif data_min >= 0:\n",
    "        cmap = LinearSegmentedColormap.from_list(\"w_g\", [\"white\", \"green\"])\n",
    "        norm = plt.Normalize(vmin=data_min, vmax=data_max)\n",
    "    # Case 3: data all non-positive → red to white\n",
    "    else:  # data_max <= 0\n",
    "        cmap = LinearSegmentedColormap.from_list(\"r_w\", [\"red\", \"white\"])\n",
    "        norm = plt.Normalize(vmin=data_min, vmax=data_max)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(data, cmap=cmap, norm=norm, aspect=\"auto\", interpolation=\"nearest\")\n",
    "    cbar = fig.colorbar(im, ax=ax)\n",
    "    cbar.set_label(\"Value\")\n",
    "\n",
    "    if xlabel: ax.set_xlabel(xlabel)\n",
    "    if ylabel: ax.set_ylabel(ylabel)\n",
    "    if title: ax.set_title(title)\n",
    "    \n",
    "    fmt = mtick.FuncFormatter(lambda x, pos: f\"{1+x/yscale:.1f}\")\n",
    "    ax.yaxis.set_major_formatter(fmt)\n",
    "    fmt = mtick.FuncFormatter(lambda x, pos: f\"{(np.exp(x/xscale)):.1f}\")\n",
    "    ax.xaxis.set_major_formatter(fmt)\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321d20e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(EV_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b380df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def permutation_test_ev(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    R: float,\n",
    "    n_perm: int = 10000,\n",
    "    seed: int | None = None,\n",
    "    bins: int = 40,\n",
    "    plot: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Monte Carlo permutation test for Expected Value (EV) of binary predictions.\n",
    "\n",
    "    EV = (R * precision - (1 - precision)), where R is a provided risk ratio.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like of shape (n_samples,)\n",
    "        Ground-truth binary labels in {0,1}. np.nan allowed (ignored).\n",
    "    y_pred : array-like of shape (n_samples,)\n",
    "        Binary predictions in {0,1}. (If you have probabilities, threshold first.)\n",
    "    R : float\n",
    "        Risk ratio to weight precision in the EV formula.\n",
    "    n_perm : int\n",
    "        Number of label permutations.\n",
    "    seed : int | None\n",
    "        RNG seed for reproducibility.\n",
    "    bins : int\n",
    "        Histogram bins for the visualization.\n",
    "    plot : bool\n",
    "        If True, show a matplotlib figure.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    results : dict\n",
    "        {\n",
    "          'actual_ev': float,\n",
    "          'perm_mean': float,\n",
    "          'perm_std': float,\n",
    "          'p_value': float,        # one-sided, P(perm >= actual)\n",
    "          'perm_evs': np.ndarray   # shape (n_perm,)\n",
    "        }\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "\n",
    "    # Keep only valid entries (ignore NaNs in y_true)\n",
    "    mask = (~np.isnan(y_true)) & np.isin(y_true, [0, 1]) & np.isin(y_pred, [0, 1])\n",
    "    y_t = y_true[mask].astype(int)\n",
    "    y_p = y_pred[mask].astype(int)\n",
    "\n",
    "    if y_t.size == 0:\n",
    "        raise ValueError(\"No valid samples after masking; check inputs.\")\n",
    "\n",
    "    def precision(tp, fp):\n",
    "        denom = tp + fp\n",
    "        return 0.0 if denom == 0 else tp / denom\n",
    "\n",
    "    def ev_from_counts(tp, fp):\n",
    "        ps = precision(tp, fp)\n",
    "        return R * ps - (1 - ps)\n",
    "\n",
    "    # Actual EV\n",
    "    tp_actual = np.sum((y_t == 1) & (y_p == 1))\n",
    "    fp_actual = np.sum((y_t == 0) & (y_p == 1))\n",
    "    actual_ev = ev_from_counts(tp_actual, fp_actual)\n",
    "\n",
    "    # Permutations\n",
    "    rng = np.random.default_rng(seed)\n",
    "    perm_evs = np.empty(n_perm, dtype=float)\n",
    "    for i in range(n_perm):\n",
    "        y_perm = rng.permutation(y_t)\n",
    "        tp = np.sum((y_perm == 1) & (y_p == 1))\n",
    "        fp = np.sum((y_perm == 0) & (y_p == 1))\n",
    "        perm_evs[i] = ev_from_counts(tp, fp)\n",
    "\n",
    "    # One-sided p-value\n",
    "    p_value = (np.sum(perm_evs >= actual_ev) + 1.0) / (n_perm + 1.0)\n",
    "\n",
    "    # Visualization\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(figsize=(7, 4.5))\n",
    "        ax.hist(perm_evs, bins=bins, density=True, alpha=0.6, color=\"#a23900c5\")\n",
    "\n",
    "        # KDE\n",
    "        x_min, x_max = float(np.min(perm_evs)), float(np.max(perm_evs))\n",
    "        xs = np.linspace(x_min, x_max, 512)\n",
    "\n",
    "        std = np.std(perm_evs)\n",
    "        n = perm_evs.size\n",
    "        bw = 1.06 * std * (n ** (-1 / 5)) if std > 0 else 0.05\n",
    "\n",
    "        if bw > 0:\n",
    "            diffs = (xs[:, None] - perm_evs[None, :]) / bw\n",
    "            kde = np.mean(np.exp(-0.5 * diffs * diffs) / (np.sqrt(2 * np.pi) * bw), axis=1)\n",
    "            ax.plot(xs, kde, linewidth=2, c='maroon')\n",
    "\n",
    "        ax.axvline(actual_ev, linewidth=4, c=\"#0075B4\")\n",
    "        ax.set_xlabel(\"EV under label permutations\")\n",
    "        ax.set_ylabel(\"Density\")\n",
    "        ax.set_title(\"Permutation Test for Expected Value (EV)\")\n",
    "        ax.text(\n",
    "            0.75, 0.95,\n",
    "            f\"actual={actual_ev:.4f}\\np={p_value:.4g}\\nmean={perm_evs.mean():.4f}\",\n",
    "            ha=\"right\", va=\"top\", transform=ax.transAxes\n",
    "        )\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return {\n",
    "        \"actual_ev\": float(actual_ev),\n",
    "        \"perm_mean\": float(perm_evs.mean()),\n",
    "        \"perm_std\": float(perm_evs.std(ddof=1)),\n",
    "        \"p_value\": float(p_value),\n",
    "        \"perm_evs\": perm_evs,\n",
    "    }\n",
    "\n",
    "# --- Example usage ---\n",
    "# y_true = np.array([0,1,1,0,1,0,1,1,0,0])\n",
    "# y_pred = np.array([0,1,0,0,1,0,1,0,0,1])\n",
    "# res = permutation_test_ev(y_true, y_pred, R=2.0, n_perm=5000, seed=42, plot=True)\n",
    "# print(res[\"p_value\"], res[\"actual_ev\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5115b133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import serialization\n",
    "data = serialization.load_deeplist(where='../../runs/run_147/ensemble.data')\n",
    "e_forest = data[0]\n",
    "e_params = data[1]\n",
    "e_thresh = data[2]\n",
    "e_freqs = data[3]\n",
    "e_EVs = data[4]\n",
    "print(e_thresh[-1])\n",
    "print(len(e_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40e15ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transforms\n",
    "import evaluation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"../../data/ES15.csv\")\n",
    "x_raw = data.values\n",
    "data_ext = pd.read_csv(\"../../data/ES15_ext.csv\")\n",
    "x_raw_ext = data_ext.values\n",
    "\n",
    "xall = transforms.forest2features(e_forest, x_raw)\n",
    "xall_ext = transforms.forest2features(e_forest, x_raw_ext)\n",
    "\n",
    "R = np.exp(np.mean(e_params[1]))\n",
    "r = np.mean(e_params[0])\n",
    "\n",
    "yext = evaluation.generate_solarr_atrplr(x_raw_ext, r, np.log(R))\n",
    "idx_ext = ~np.isnan(yext)\n",
    "yext = yext[idx_ext]\n",
    "xall_ext = xall_ext[idx_ext]\n",
    "\n",
    "ytrue = evaluation.generate_solarr_atrplr(x_raw, r, np.log(R))\n",
    "idx = ~np.isnan(ytrue)\n",
    "ytrue = ytrue[idx]\n",
    "xall = xall[idx]\n",
    "\n",
    "\n",
    "\n",
    "xall = evaluation.binarize_features(xall, ytrue)\n",
    "xall_ext = evaluation.binarize_features(xall_ext, yext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e64ab1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(yext), type(ypred_ext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bf29f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = e_thresh[-1]\n",
    "\n",
    "ypred = evaluation.meta_bithreshold(xall, thr)\n",
    "ypred_ext = evaluation.meta_bithreshold(xall_ext, thr)\n",
    "\n",
    "permutation_test_ev(ytrue, ypred, R=R, n_perm=2000, bins=9)\n",
    "#print(evaluation.solve_EV(ytrue, ypred, R))\n",
    "permutation_test_ev(yext, ypred_ext, R=R, n_perm=10000, bins=9)\n",
    "#print(evaluation.solve_EV(yext, ypred_ext, R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5622ea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "thr2 = thr*3\n",
    "\n",
    "ypred = evaluation.meta_bithreshold(xall, thr2)\n",
    "ypred_ext = evaluation.meta_bithreshold(xall_ext, thr2)\n",
    "permutation_test_ev(ytrue, ypred, R=R, n_perm=2000, bins=9)\n",
    "#print(evaluation.solve_EV(ytrue, ypred, R))\n",
    "permutation_test_ev(yext, ypred_ext, R=R, n_perm=5000, bins=9)\n",
    "np.unique(ypred_ext, return_counts=True)\n",
    "#print(evaluation.solve_EV(yext, ypred_ext, R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b227c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import serialization, transforms, evaluation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "bests = [145, 148, 150, 155, 163, 169, 173]\n",
    "\n",
    "allforests = []\n",
    "allperfs = []\n",
    "allEVs = []\n",
    "allFreqs = []\n",
    "allpvals = []\n",
    "initthrs = []\n",
    "allparams = []\n",
    "\n",
    "data_ext = pd.read_csv(\"../../data/ES15_ext.csv\")\n",
    "x_raw_ext = data_ext.values\n",
    "\n",
    "\n",
    "for i in range(145, 179):\n",
    "    here = i\n",
    "    print(i)\n",
    "    where = str(i)\n",
    "    if i==170:\n",
    "        continue\n",
    "    try:\n",
    "        data = serialization.load_deeplist(where='../../runs/run_'+where+'/ensemble.data')\n",
    "        #print(data[1:])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    e_forest = data[0]\n",
    "    e_params = data[1]\n",
    "    e_thresh = data[2]\n",
    "    e_freqs = data[3]\n",
    "    e_EVs = data[4]\n",
    "\n",
    "    if(len(e_forest)==0):\n",
    "        print('skip ', {i})\n",
    "        continue\n",
    "\n",
    "    allforests.append(data[0])\n",
    "    \n",
    "    initthrs.append(e_thresh[-1])\n",
    "\n",
    "    xall_ext = transforms.forest2features(e_forest, x_raw_ext)\n",
    "\n",
    "    R = np.exp(np.mean(e_params[1]))\n",
    "    r = np.mean(e_params[0])\n",
    "\n",
    "    allparams.append((r, np.log(R)))\n",
    "\n",
    "    \n",
    "    yext = evaluation.generate_solarr_atrplr(x_raw_ext, r, np.log(R))\n",
    "    idx_ext = ~np.isnan(yext)\n",
    "    yext = yext[idx_ext]\n",
    "    xall_ext = xall_ext[idx_ext]\n",
    "    xall_ext = evaluation.binarize_features(xall_ext, yext)\n",
    "\n",
    "    perf = evaluation.ensemble_performance_scarcethresh(xall_ext, yext, e_thresh[-1], R)\n",
    "    perf = np.asarray(perf)\n",
    "    if(perf.size == 0):\n",
    "        continue\n",
    "\n",
    "    for i in range(perf.shape[0]):\n",
    "        #EV\n",
    "        if(perf[i, 1] == -1):\n",
    "            allEVs.append(perf[:i])\n",
    "            break\n",
    "        elif(i == perf.shape[0]-1):\n",
    "            allEVs.append(perf[:i+1])\n",
    "\n",
    "    for i in range(perf.shape[0]):\n",
    "        #freq\n",
    "        if(perf[i, 2] == 0):\n",
    "            allFreqs.append(perf[:i])\n",
    "            break\n",
    "        elif(i == perf.shape[0]-1):\n",
    "            allFreqs.append(perf[:i+1])\n",
    "\n",
    "    start = 0\n",
    "    for i in range(1, perf.shape[0]):\n",
    "        #p values\n",
    "        if(perf[i, 3] > perf[i-1, 3] and perf[i, 3] == 1):\n",
    "            allpvals.append(perf[start:i])\n",
    "            break\n",
    "        elif(perf[i, 3] ==1):\n",
    "            start = i\n",
    "        elif(i == perf.shape[0]-1):\n",
    "            allpvals.append(perf[start:i+1])\n",
    "\n",
    "    #print(len(allforests), len(allparams), len(initthrs))\n",
    "    \n",
    "    allperfs.append(perf)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206e54fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(allforests), len(initthrs), len(allparams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc62801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualization\n",
    "\n",
    "datasets = []\n",
    "for perf in allEVs:\n",
    "    datasets.append((perf[:, 0], perf[:, 1]))\n",
    "\n",
    "_, _ = visualization.plot_spec_ensemble_performances(datasets, info='EV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a9182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pval_datasets = []\n",
    "for perf in allpvals:\n",
    "    pval_datasets.append((perf[:, 0], perf[:, 3]))\n",
    "\n",
    "_, _ = visualization.plot_spec_ensemble_performances(pval_datasets, info='P-Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176a7460",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_datasets = []\n",
    "for perf in allFreqs:\n",
    "    freq_datasets.append((perf[:, 0], perf[:, 2]))\n",
    "    \n",
    "_, _ = visualization.plot_spec_ensemble_performances(freq_datasets, info='Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0118154c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualization\n",
    "for i in e_forest:\n",
    "    some_tree = i\n",
    "    latexstr = visualization.to_latex(some_tree)\n",
    "    visualization.render_latex(latexstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3e9dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import serialization, visualization  # adjust to your actual imports\n",
    "\n",
    "def save_forests_and_latex(runs=range(151, 212)):\n",
    "    for i in runs:\n",
    "        where = str(i)\n",
    "        run_dir = f\"../../runs/run_{where}\"\n",
    "        \n",
    "        # Load forest\n",
    "        try:\n",
    "            data = serialization.load_deeplist(where=os.path.join(run_dir, \"ensemble.data\"))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "        e_forest = data[0]\n",
    "\n",
    "        # Prepare subfolder for images\n",
    "        img_dir = os.path.join(run_dir, \"latex_images\")\n",
    "        os.makedirs(img_dir, exist_ok=True)\n",
    "\n",
    "        # Text file for LaTeX strings\n",
    "        latex_file = os.path.join(run_dir, \"latex_strings.txt\")\n",
    "        with open(latex_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            for tree_idx, tree in enumerate(e_forest):\n",
    "                # Convert to LaTeX\n",
    "                latex_str = visualization.to_latex(tree)\n",
    "                f.write(latex_str + \"\\n\\n\")  # save string\n",
    "\n",
    "                # Render LaTeX as image\n",
    "                img_path = os.path.join(img_dir, f\"tree_{tree_idx}.png\")\n",
    "                visualization.render_latex(latex_str, filename=img_path)\n",
    "\n",
    "        print(f\"Run {where}: saved {len(e_forest)} trees -> {img_dir}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a90eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_forests_and_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0c7d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)   # reset all rcParams to defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32563a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestidx = []\n",
    "bestthresh = []\n",
    "for i in range(len(pval_datasets)):\n",
    "    #print('IN ', idx)\n",
    "    #print(i[0])\n",
    "    #print(i[1])\n",
    "    if(pval_datasets[i][1][list(pval_datasets[i][1]).index(min(pval_datasets[i][1]))] < 0.01 and freq_datasets[i][1][list(pval_datasets[i][1]).index(min(pval_datasets[i][1]))] < 0.5):\n",
    "        bestidx.append(i)\n",
    "        bestthresh.append(pval_datasets[i][0][list(pval_datasets[i][1]).index(min(pval_datasets[i][1]))])\n",
    "print(bestidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28189c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transforms\n",
    "\n",
    "data = pd.read_csv(\"../../data/ES15.csv\")\n",
    "x_raw = data.values\n",
    "\n",
    "xlist = []\n",
    "\n",
    "for f in range(len(allforests)):\n",
    "    xnew = transforms.forest2features(allforests[f], x_raw)\n",
    "    xlist.append(xnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d3a6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xextlist = []\n",
    "\n",
    "for f in range(len(allforests)):\n",
    "    xextnew = transforms.forest2features(allforests[f], x_raw_ext)\n",
    "    xextlist.append(xextnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95b67fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def gaussian_smooth_1d(y, sigma_pts=3):\n",
    "    # sigma_pts is in \"grid points\" (not data units)\n",
    "    if sigma_pts <= 0:\n",
    "        return y\n",
    "    half = int(np.ceil(4 * sigma_pts))\n",
    "    t = np.arange(-half, half + 1)\n",
    "    k = np.exp(-0.5 * (t / sigma_pts) ** 2)\n",
    "    k /= k.sum()\n",
    "    return np.convolve(y, k, mode=\"same\")\n",
    "\n",
    "def permutation_test_ev_multi_normed(\n",
    "    x_raw,\n",
    "    X_list,               # list of np.ndarrays (one per model); each aligned row-wise to x_raw\n",
    "    thresh_list,          # list[float] thresholds for evaluation.meta_bithreshold\n",
    "    prms,                 # list[tuple] per-model params -> (p0, p1) for generate_solarr_atrplr\n",
    "    n_perm: int = 1000,\n",
    "    seed: int | None = None,\n",
    "    bins: int = 25,\n",
    "    plot: bool = True,\n",
    "    labels: list[str] | None = None,   # kept for API compat; not used in legend now\n",
    "):\n",
    "    \"\"\"\n",
    "    For each model i:\n",
    "      ytrue_full = evaluation.generate_solarr_atrplr(x_raw, prms[i][0], prms[i][1])\n",
    "      idx = ~np.isnan(ytrue_full)\n",
    "      ytrue = ytrue_full[idx]\n",
    "      xall  = X_list[i][idx]\n",
    "      xall  = evaluation.binarize_features(xall, ytrue)\n",
    "      ypred = evaluation.meta_bithreshold(xall, thresh_list[i])\n",
    "\n",
    "    Then compute EV and its label-permutation null (keeping ypred fixed),\n",
    "    z-score normalize each model's permutation distribution, pool all z's to\n",
    "    one histogram/KDE, and draw vertical lines at each model's *own* z-actual.\n",
    "\n",
    "    Plotting change: suppress per-model legend spam. Instead, show a single\n",
    "    median summary (median z, p, EV) and one median vertical line in the legend.\n",
    "    \"\"\"\n",
    "    if labels is not None and len(labels) != len(X_list):\n",
    "        raise ValueError(\"labels length must match X_list length\")\n",
    "    if len(X_list) != len(thresh_list) or len(X_list) != len(prms):\n",
    "        raise ValueError(\"X_list, thresh_list, and prms must have the same length\")\n",
    "\n",
    "    def precision(tp, fp):\n",
    "        den = tp + fp\n",
    "        return 0.0 if den == 0 else tp / den\n",
    "\n",
    "    def ev_from_counts(tp, fp, R):\n",
    "        ps = precision(tp, fp)\n",
    "        return R * ps - (1 - ps)\n",
    "\n",
    "    base_rng = np.random.default_rng(seed)\n",
    "    model_seeds = base_rng.integers(0, 2**63 - 1, size=len(X_list), dtype=np.int64)\n",
    "\n",
    "    per_model = []\n",
    "    pooled_perm_z = []   # collect z-scored permutation EVs from all models\n",
    "    z_lines = []         # (idx, z_actual) for plotting verticals\n",
    "\n",
    "    for i, (xall_full, thr, param_pair) in enumerate(zip(X_list, thresh_list, prms)):\n",
    "        print(i)\n",
    "        # 1) generate ytrue from raw + params\n",
    "        ytrue_full = evaluation.generate_solarr_atrplr(x_raw, param_pair[0], param_pair[1])\n",
    "\n",
    "        # 2) mask valid\n",
    "        idx = ~np.isnan(ytrue_full)\n",
    "        ytrue = np.asarray(ytrue_full[idx]).astype(float)\n",
    "        xall  = np.asarray(xall_full)[idx]\n",
    "\n",
    "        # enforce binary conversion for features relative to ytrue\n",
    "        xall = evaluation.binarize_features(xall, ytrue)\n",
    "\n",
    "        # 3) predictions\n",
    "        ypred = np.asarray(evaluation.meta_bithreshold(xall, thr))\n",
    "\n",
    "        # 4) finalize mask to valid binary\n",
    "        mask = np.isin(ypred, [0, 1]) & np.isin(ytrue, [0.0, 1.0])\n",
    "        y_t = ytrue[mask].astype(int)\n",
    "        y_p = ypred[mask].astype(int)\n",
    "\n",
    "        if y_t.size == 0:\n",
    "            raise ValueError(f\"Model {i}: no valid samples after masking; check inputs and shapes.\")\n",
    "\n",
    "        # actual EV (R derived from ln_plratio via exp)\n",
    "        R = float(np.exp(param_pair[1]))\n",
    "        tp_actual = np.sum((y_t == 1) & (y_p == 1))\n",
    "        fp_actual = np.sum((y_t == 0) & (y_p == 1))\n",
    "        actual_ev = ev_from_counts(tp_actual, fp_actual, R)\n",
    "\n",
    "        # permutations (labels only)\n",
    "        rng = np.random.default_rng(int(model_seeds[i]))\n",
    "        perm_evs = np.empty(n_perm, dtype=float)\n",
    "        for k in range(n_perm):\n",
    "            y_perm = rng.permutation(y_t)\n",
    "            tp = np.sum((y_perm == 1) & (y_p == 1))\n",
    "            fp = np.sum((y_perm == 0) & (y_p == 1))\n",
    "            perm_evs[k] = ev_from_counts(tp, fp, R)\n",
    "\n",
    "        perm_mean = float(perm_evs.mean())\n",
    "        perm_std  = float(perm_evs.std(ddof=1))\n",
    "        eps = 1e-12\n",
    "        denom = perm_std if perm_std > 0 else eps\n",
    "\n",
    "        # normalize this model's distribution and its actual to z-space\n",
    "        perm_z = (perm_evs - perm_mean) / denom\n",
    "        z_actual = (actual_ev - perm_mean) / denom\n",
    "\n",
    "        # one-sided p-value under this model's null\n",
    "        p_value = (np.sum(perm_evs >= actual_ev) + 1.0) / (n_perm + 1.0)\n",
    "\n",
    "        pooled_perm_z.append(perm_z)\n",
    "        z_lines.append((i, float(z_actual)))\n",
    "\n",
    "        per_model.append({\n",
    "            \"actual_ev\": float(actual_ev),\n",
    "            \"perm_mean\": perm_mean,\n",
    "            \"perm_std\":  perm_std,\n",
    "            \"z_actual\":  float(z_actual),\n",
    "            \"p_value\":   float(p_value),\n",
    "            \"n_kept\":    int(y_t.size),\n",
    "            \"perm_evs\":  perm_evs,   # raw (un-normalized) per-model null if you need it later\n",
    "        })\n",
    "\n",
    "    # ---- pooled normalized null ----\n",
    "    pooled_perm_z = np.concatenate(pooled_perm_z, axis=0) if pooled_perm_z else np.array([])\n",
    "\n",
    "    # ---- visualization ----\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(figsize=(8.0, 5.0))\n",
    "\n",
    "        # single pooled null (all models' permutation EVs, z-scored within-model)\n",
    "        if pooled_perm_z.size > 0:\n",
    "            ax.hist(pooled_perm_z, color='maroon', bins=bins, density=True, alpha=0.3, label=\"Pooled null (z)\")\n",
    "\n",
    "            # simple Gaussian KDE\n",
    "            xs = np.linspace(float(pooled_perm_z.min()), float(pooled_perm_z.max()), 512)\n",
    "            std = np.std(pooled_perm_z)\n",
    "            n = pooled_perm_z.size\n",
    "            bw = 1.06 * std * (n ** (-1/5)) if std > 0 else 0.15\n",
    "            if bw > 0:\n",
    "                diffs = (xs[:, None] - pooled_perm_z[None, :]) / bw\n",
    "                kde = np.mean(np.exp(-0.5 * diffs * diffs) / (np.sqrt(2*np.pi) * bw), axis=1)\n",
    "                kde = gaussian_smooth_1d(kde, 25)\n",
    "                ax.plot(xs, kde, color='maroon', linewidth=2, label=\"KDE (pooled z)\")\n",
    "\n",
    "        # vertical lines for each model at its own z-actual (no labels to avoid legend spam)\n",
    "        for _, z_act in z_lines:\n",
    "            ax.axvline(z_act, color='steelblue', linewidth=1.5, alpha=0.3)\n",
    "\n",
    "        # ---- median summary across models ----\n",
    "        z_vals   = np.array([z for _, z in z_lines], dtype=float) if z_lines else np.array([])\n",
    "        p_vals   = np.array([pm[\"p_value\"] for pm in per_model], dtype=float) if per_model else np.array([])\n",
    "        ev_vals  = np.array([pm[\"actual_ev\"] for pm in per_model], dtype=float) if per_model else np.array([])\n",
    "\n",
    "        if z_vals.size > 0:\n",
    "            z_med  = float(np.median(z_vals))\n",
    "            p_med  = float(np.median(p_vals)) if p_vals.size else np.nan\n",
    "            ev_med = float(np.median(ev_vals)) if ev_vals.size else np.nan\n",
    "\n",
    "            # one bold median line with the ONLY legend entry\n",
    "            ax.axvline(z_med, linewidth=4, color=\"black\", label=\"median across models\")\n",
    "\n",
    "            # compact annotation box with median stats\n",
    "            ax.text(\n",
    "                0.98, 0.95,\n",
    "                f\"models: {len(z_vals)+1}\\n\"\n",
    "                f\"median z = {z_med:.2f}\\n\"\n",
    "                f\"median p = {p_med:.3g}\\n\"\n",
    "                f\"median EV = {ev_med:.4f}\",\n",
    "                ha=\"right\", va=\"top\", transform=ax.transAxes,\n",
    "                bbox=dict(facecolor=\"white\", alpha=0.8, edgecolor=\"none\", boxstyle=\"round,pad=0.4\")\n",
    "            )\n",
    "\n",
    "        ax.set_xlabel(\"z(EV) relative to each model's own permutation null\")\n",
    "        ax.set_title(\"Permutation Test for EV — pooled normalized null + model z-lines\")\n",
    "        ax.legend(loc=\"best\", fontsize=9)  # will contain at most 1–2 items\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # compact matrix [actual_ev, perm_mean, perm_std, z_actual, p_value]\n",
    "    summary = np.array(\n",
    "        [[pm[\"actual_ev\"], pm[\"perm_mean\"], pm[\"perm_std\"], pm[\"z_actual\"], pm[\"p_value\"]] for pm in per_model],\n",
    "        dtype=float\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"per_model\": per_model,\n",
    "        \"summary\": summary,\n",
    "        \"pooled_perm_z\": pooled_perm_z,   # the single displayed distribution\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfd898a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x = []\n",
    "t = []\n",
    "p = []\n",
    "\n",
    "for i in range(len(xextlist)):\n",
    "    if i in bestidx:\n",
    "        x.append(xextlist[i])\n",
    "        p.append(allparams[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e111ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(xextlist))\n",
    "print(len(x), len(bestthresh), len(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8080c292",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = permutation_test_ev_multi_normed(x_raw_ext, x, bestthresh, p, bins=16, n_perm=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a8a783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def permutation_test_ev_single(y_true, y_pred, R, n_perm=2000, seed=None):\n",
    "    \"\"\"\n",
    "    Compute permutation p-value for EV at a single prediction vector.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    mask = (~np.isnan(y_true))\n",
    "    y_t = y_true[mask].astype(int)\n",
    "    y_p = y_pred[mask].astype(int)\n",
    "\n",
    "    def precision(tp, fp):\n",
    "        denom = tp + fp\n",
    "        return 0.0 if denom == 0 else tp / denom\n",
    "\n",
    "    def ev_from_counts(tp, fp):\n",
    "        ps = precision(tp, fp)\n",
    "        return R * ps - (1 - ps)\n",
    "\n",
    "    # Actual EV\n",
    "    tp_actual = np.sum((y_t == 1) & (y_p == 1))\n",
    "    fp_actual = np.sum((y_t == 0) & (y_p == 1))\n",
    "    actual_ev = ev_from_counts(tp_actual, fp_actual)\n",
    "\n",
    "    # Permutations\n",
    "    perm_evs = np.empty(n_perm, dtype=float)\n",
    "    for i in range(n_perm):\n",
    "        y_perm = rng.permutation(y_t)\n",
    "        tp = np.sum((y_perm == 1) & (y_p == 1))\n",
    "        fp = np.sum((y_perm == 0) & (y_p == 1))\n",
    "        perm_evs[i] = ev_from_counts(tp, fp)\n",
    "\n",
    "    # One-sided p-value\n",
    "    p_value = (np.sum(perm_evs >= actual_ev) + 1.0) / (n_perm + 1.0)\n",
    "    return p_value\n",
    "\n",
    "\n",
    "def build_pval_grid(x_raw, best_trees, m=10, n=30, \n",
    "                    yffset=10, xffset=0, yscale=10, xscale=10, \n",
    "                    n_perm=2000, seed=None):\n",
    "    \"\"\"\n",
    "    Builds a grid of permutation test p-values for EV.\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import precision_score\n",
    "    xall = np.asarray(best_trees).T\n",
    "    pval_arr = np.empty((m, n))\n",
    "\n",
    "    for i in range(yffset, m+yffset):\n",
    "        for j in range(xffset, n+xffset):\n",
    "\n",
    "            atrthr = i / yscale\n",
    "            ln_plr = j / xscale\n",
    "\n",
    "            # Generate candidate solution\n",
    "            y_ = evaluation.generate_solarr_atrplr(x_raw, atrthr, ln_plr)\n",
    "            idx = ~np.isnan(y_)\n",
    "            y_ = y_[idx]\n",
    "\n",
    "            # Candidate predictions\n",
    "            pvpred = evaluation.meta_bipopvote(xall[idx], threshold=0.99)\n",
    "\n",
    "            # Precision\n",
    "            ps = precision_score(y_, pvpred)\n",
    "\n",
    "            # Risk ratio\n",
    "            R = float(np.exp(ln_plr))\n",
    "\n",
    "            # Permutation test for EV → p-value\n",
    "            pval = permutation_test_ev_single(y_, pvpred, R, n_perm=n_perm, seed=seed)\n",
    "\n",
    "            # Store in array\n",
    "            pval_arr[i-yffset, j-xffset] = pval\n",
    "\n",
    "    return pval_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b145b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pval_grid = build_pval_grid(x_raw, best_trees, m=10, n=30,\n",
    "    yffset=10, xffset=0,\n",
    "    yscale=10, xscale=10,\n",
    "    n_perm=1000,  # more perms = smoother p-values\n",
    "    seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72948574",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(pval_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d566dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lnplr = 10\n",
    "\n",
    "y_ = evaluation.generate_solarr_atrplr(x_raw, 1, np.log(lnplr))\n",
    "idx = ~np.isnan(y_)\n",
    "\n",
    "y_ = y_[idx]\n",
    "pvpred = evaluation.meta_bipopvote(xall[idx], threshold=0.99)\n",
    "\n",
    "v, c = np.unique(pvpred, return_counts=True)\n",
    "print(v, c)\n",
    "ps = precision_score(y_, pvpred)\n",
    "print(ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928341a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap, TwoSlopeNorm\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def visualize_loss_topology_3d_heatmap(\n",
    "    Z: np.ndarray,\n",
    "    title: str = \"3D Heatmap (Desirability)\",\n",
    "    extent: tuple | None = None,      # (xmin, xmax, ymin, ymax)\n",
    "    elev: float = 35,\n",
    "    azim: float = 135,\n",
    "    stride: int = 1,                   # plot every Nth point\n",
    "    nan_color: str = \"#FFFFFF\",\n",
    "    dpi: int = 160,\n",
    "    ticks: list[float] | None = None   # custom colorbar ticks (optional)\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots a 3D surface colored as a 'heatmap' with:\n",
    "      - red↔white↔green when data spans negative and positive (center at 0)\n",
    "      - white→green when all non-negative\n",
    "      - red→white when all non-positive\n",
    "\n",
    "    Z: 2D array (can include NaNs)\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- validate & prep ----\n",
    "    Z = np.asarray(Z, dtype=float)\n",
    "    if Z.ndim != 2:\n",
    "        raise ValueError(\"Z must be 2D.\")\n",
    "    if not np.isfinite(Z).any():\n",
    "        raise ValueError(\"Z contains no finite values.\")\n",
    "\n",
    "    m, n = Z.shape\n",
    "    if extent is None:\n",
    "        x = np.arange(n); y = np.arange(m)\n",
    "    else:\n",
    "        xmin, xmax, ymin, ymax = extent\n",
    "        x = np.linspace(xmin, xmax, n)\n",
    "        y = np.linspace(ymin, ymax, m)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "\n",
    "    data_min = float(np.nanmin(Z))\n",
    "    data_max = float(np.nanmax(Z))\n",
    "\n",
    "    # ---- colormap + normalization per your spec ----\n",
    "    if data_min < 0 < data_max:\n",
    "        cmap = LinearSegmentedColormap.from_list(\"r_w_g\", [\"#7F0000\", \"#F0F0F0\", \"#0087B4\"])\n",
    "        norm = TwoSlopeNorm(vmin=data_min, vcenter=0.0, vmax=data_max)\n",
    "    elif data_min >= 0:\n",
    "        cmap = LinearSegmentedColormap.from_list(\"r_w_g\", [\"#0087B4\", \"white\", \"#7F0000\"])\n",
    "        norm = TwoSlopeNorm(vmin=data_min, vcenter=0.05, vmax=data_max)\n",
    "    else:  # data_max <= 0\n",
    "        cmap = LinearSegmentedColormap.from_list(\"r_w\", [\"red\", \"white\"])\n",
    "        norm = plt.Normalize(vmin=data_min, vmax=data_max)\n",
    "\n",
    "    cmap.set_bad(nan_color)\n",
    "\n",
    "    # ---- optional downsample for speed ----\n",
    "    sl = slice(0, None, max(1, stride))\n",
    "    Xs, Ys, Zs = X[sl, sl], Y[sl, sl], Z[sl, sl]\n",
    "\n",
    "    # ---- figure (no constrained/tight layout to avoid colorbar engine clashes) ----\n",
    "    fig = plt.figure(figsize=(8, 6), dpi=dpi)\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "    # 3D surface colored by heatmap scheme\n",
    "    surf = ax.plot_surface(\n",
    "        Xs, Ys, Zs,\n",
    "        cmap=cmap, norm=norm,\n",
    "        linewidth=0, antialiased=True, shade=True\n",
    "    )\n",
    "\n",
    "    # ---- stable colorbar on a dedicated axis ----\n",
    "    sm = ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array(Z)\n",
    "    sm.set_clim(data_min, data_max)\n",
    "    cbar = fig.colorbar(sm, ax=ax, shrink=0.8, pad=0.1)\n",
    "\n",
    "    # default ticks: min, (−1 if in-range), 0 if in-range, max — or user-supplied\n",
    "    if ticks is None:\n",
    "        candidates = [data_min, 0.0, data_max]\n",
    "        # include -1 only if it lies within [data_min, data_max]\n",
    "        if data_min <= -1.0 <= data_max:\n",
    "            candidates.insert(1, -1.0)\n",
    "        ticks = sorted(set(t for t in candidates if data_min <= t <= data_max))\n",
    "\n",
    "    cbar.set_ticks(ticks)\n",
    "    # friendly labels\n",
    "    labels = []\n",
    "    for t in ticks:\n",
    "        if np.isclose(t, 0.0) and (data_min < 0 < data_max):\n",
    "            labels.append(\"neutral (0)\")\n",
    "        elif np.isclose(t, -1.0):\n",
    "            labels.append(\"worst (-1)\")\n",
    "        elif np.isclose(t, data_min):\n",
    "            labels.append(f\"min ({t:g})\")\n",
    "        elif np.isclose(t, data_max):\n",
    "            labels.append(f\"max ({t:g})\")\n",
    "        else:\n",
    "            labels.append(f\"{t:g}\")\n",
    "    cbar.set_ticklabels(labels)\n",
    "    cbar.set_label(\"Desirability (higher is better)\")\n",
    "\n",
    "    # ---- view & axes ----\n",
    "    ax.set_title(title, pad=10)\n",
    "    if extent is not None:\n",
    "        ax.set_xlim(x.min(), x.max()); ax.set_ylim(y.min(), y.max())\n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad96e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_loss_topology_3d_heatmap(pval_grid, elev=30, azim=110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833dab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def shapley_ev_allvote(\n",
    "    X: np.ndarray,           # (n_samples, n_models) in {0,1}\n",
    "    y_true: np.ndarray,      # (n_samples,) in {0,1}\n",
    "    R: float = 6.0,\n",
    "    n_permutations: int = 256,\n",
    "    seed: int | None = None,\n",
    "    return_kind: str = \"both\"   # \"both\", \"shapley\", or \"importance\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Monte Carlo Shapley values for model contributions to an ALL-vote (AND) ensemble,\n",
    "    where coalition predictions are 1 iff *all* included models predict 1.\n",
    "    Score = EV from precision: EV = (R+1)*P - 1.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    If return_kind == \"both\": dict with keys:\n",
    "        - \"shapley\": np.ndarray (n_models,) raw Shapley contributions (EV units)\n",
    "        - \"importance\": np.ndarray (n_models,) normalized to [0,1] (positive part)\n",
    "        - \"ev_full\": float, EV of the full coalition (all models)\n",
    "    If \"shapley\": np.ndarray (n_models,)\n",
    "    If \"importance\": np.ndarray (n_models,)\n",
    "    \"\"\"\n",
    "    X = (X.astype(np.uint8) != 0)\n",
    "    y = (np.asarray(y_true).astype(np.uint8) != 0)\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n_samples, n_models = X.shape\n",
    "\n",
    "    # ---- helper to compute EV from TP/FP (precision-only) ----\n",
    "    def ev_from_counts(tp: float, fp: float) -> float:\n",
    "        denom = tp + fp\n",
    "        if denom <= 0.0:\n",
    "            return 0.0\n",
    "        P = tp / denom\n",
    "        return P * (R + 1.0) - 1.0\n",
    "\n",
    "    # Precompute full-coalition EV (AND across all models)\n",
    "    p_full = X.all(axis=1)\n",
    "    tp_full = float(np.sum(p_full & y))\n",
    "    fp_full = float(np.sum(p_full & (~y)))\n",
    "    ev_full = ev_from_counts(tp_full, fp_full)\n",
    "\n",
    "    # For incremental updates, we keep the current coalition mask (boolean over samples)\n",
    "    # and track EV via TP/FP counts for that mask.\n",
    "    # NOTE: Base coalition (empty set) uses vacuous truth for AND → all True mask.\n",
    "    # Adding first model j yields mask = X[:, j], as desired.\n",
    "\n",
    "    shapley_sum = np.zeros(n_models, dtype=np.float64)\n",
    "\n",
    "    # Optional precomputations to reduce repeated ANDs with y / ~y\n",
    "    X_and_y    = X & y[:, None]     # shape: (n_samples, n_models)\n",
    "    X_and_ny   = X & (~y)[:, None]\n",
    "\n",
    "    for _ in range(n_permutations):\n",
    "        order = rng.permutation(n_models)\n",
    "\n",
    "        # start from empty coalition (mask = all True)\n",
    "        mask = np.ones(n_samples, dtype=bool)\n",
    "        # counts for empty coalition\n",
    "        tp_cur = float(np.sum(mask & y))\n",
    "        fp_cur = float(np.sum(mask & (~y)))\n",
    "        ev_cur = ev_from_counts(tp_cur, fp_cur)\n",
    "\n",
    "        for j in order:\n",
    "            # New mask = old mask AND model j's predictions\n",
    "            # We need TP/FP for the new mask quickly.\n",
    "            # TP_next = sum(mask & X[:,j] & y) = sum((mask & y) & X[:,j])\n",
    "            # FP_next = sum(mask & X[:,j] & ~y) = sum((mask & ~y) & X[:,j])\n",
    "\n",
    "            # Compute masked sums via boolean indexing (fast in NumPy)\n",
    "            # First restrict to current mask; then sum X_and_y / X_and_ny columns j\n",
    "            idx = mask\n",
    "            tp_next = float(np.sum(X_and_y[idx, j]))\n",
    "            fp_next = float(np.sum(X_and_ny[idx, j]))\n",
    "\n",
    "            ev_next = ev_from_counts(tp_next, fp_next)\n",
    "            marginal = ev_next - ev_cur\n",
    "            shapley_sum[j] += marginal\n",
    "\n",
    "            # Advance coalition\n",
    "            # (mask & X[:, j]) updates in-place efficiently\n",
    "            mask[idx] &= X[idx, j]\n",
    "            tp_cur, fp_cur, ev_cur = tp_next, fp_next, ev_next\n",
    "\n",
    "    shapley = shapley_sum / float(n_permutations)\n",
    "\n",
    "    # Importance on [0,1]: normalize positive contributions\n",
    "    pos = np.clip(shapley, 0.0, None)\n",
    "    imax = pos.max()\n",
    "    importance = (pos / imax) if imax > 0 else np.zeros_like(pos)\n",
    "\n",
    "    if return_kind == \"shapley\":\n",
    "        return shapley\n",
    "    if return_kind == \"importance\":\n",
    "        return importance\n",
    "    return {\"shapley\": shapley, \"importance\": importance, \"ev_full\": ev_full}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e556a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "imporances = shapley_ev_allvote(xall, ytrue, return_kind=\"both\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e161cb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances= shapley_ev_allvote(xall_ext, yext, return_kind=\"both\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e9e194",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imporances['shapley'])\n",
    "print(imporances['shapley'].sum())\n",
    "print(imporances['ev_full'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba767554",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True, precision=6)\n",
    "print(importances['shapley'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4564399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "newidx = np.where(imporances > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acefe556",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(newidx)\n",
    "print(imporances[newidx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1ea514",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(xall, y_, test_size=0.3, shuffle=True, random_state=0)\n",
    "#scaler = StandardScaler()\n",
    "#X_train = scaler.fit_transform(X_train)\n",
    "#X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5095d765",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history = evaluation.standard_NN_construction(X_train, y_train, epochs=50, verbose=1)\n",
    "evaluation.standard_NN_evaluation(X_train, X_test, y_train, y_test, model, history, run_dir='', vizout=False, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5e1566",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(preds, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837c80e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(x_[:, 0]).hist(bins=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feea78ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms.get_oplist(forest[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79c5826",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,1):\n",
    "    print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8e31a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import serialization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path, scores = serialization.load_deeplist(where='../../runs/run_26/path_pscr.hstry')\n",
    "\n",
    "plt.plot(range(len(scores)), scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e344ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../../data/ES15.csv\")\n",
    "x_raw = data.values\n",
    "best_forest = serialization.load_forest(where='../../runs/run_49/best.4st')\n",
    "import optimize\n",
    "x_ = transforms.forest2features(\n",
    "    population=best_forest,\n",
    "    x_raw=x_raw\n",
    ")\n",
    "_, __, best_scores = evaluation.evaluate_forest_newer(x_, close_prices=x_raw[:, 3], lag_range=(1, 3))\n",
    "loss = optimize.loss_fc(best_scores)\n",
    "print(loss)\n",
    "\n",
    "for i in range(len(best_forest)):\n",
    "    print(transforms.get_oplist(best_forest[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0130c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# label train‐vs‐test rows\n",
    "X_tv = np.vstack([X_train, X_test])\n",
    "y_tv = np.array([0]*len(X_train) + [1]*len(X_test))\n",
    "adv = LogisticRegression().fit(X_tv, y_tv)\n",
    "print(\"AUC distinguishing train vs test:\", adv.score(X_tv, y_tv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a61505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from transforms import forest2features\n",
    "\n",
    "# 1) Define the transformer that wraps your feature generator\n",
    "class Forest2Features(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, population):\n",
    "        self.population = population\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # X is your raw x_raw array (n_samples, 4)\n",
    "        return forest2features(self.population, X)\n",
    "\n",
    "# 2) Prepare your raw data and target\n",
    "#    Assume x_raw is an (N, 4) ndarray and best_forest is defined\n",
    "#    Column 2 is the 'close' price\n",
    "raw_prices = x_raw[:, 3]\n",
    "# compute 1-step log-return target of length N-1\n",
    "y_logret = np.log(raw_prices[1:] / raw_prices[:-1])\n",
    "# align features by dropping the last raw row so X_raw_aligned.shape[0] == y_logret.shape[0]\n",
    "X_raw_aligned = x_raw[:-1, :]\n",
    "\n",
    "noise = np.random.rand(X_raw_aligned.shape[0], 1)\n",
    "\n",
    "X_raw_aligned = np.hstack([X_raw_aligned, noise])\n",
    "\n",
    "# 3) Build the pipeline\n",
    "pipe = Pipeline([\n",
    "    (\"fe\",     Forest2Features(population=best_forest)),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"lr\",     LinearRegression())\n",
    "])\n",
    "\n",
    "# 4) Time-series cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "for fold, (train_idx, test_idx) in enumerate(tscv.split(X_raw_aligned), 1):\n",
    "    X_tr, X_te = X_raw_aligned[train_idx], X_raw_aligned[test_idx]\n",
    "    y_tr, y_te = y_logret     [train_idx], y_logret     [test_idx]\n",
    "\n",
    "    #y_tr = np.random.permutation(y_tr)\n",
    "\n",
    "    pipe.fit(X_tr, y_tr)\n",
    "    \n",
    "    perm = permutation_importance(pipe,\n",
    "                              X_tr, y_tr,\n",
    "                              n_repeats=5,\n",
    "                              random_state=0,\n",
    "                              scoring='r2')\n",
    "    perm_importances = pd.Series(perm.importances_mean)\n",
    "    print(perm_importances)\n",
    "    #print(\"impt: \",perm_importances.max(),perm_importances[4])\n",
    "\n",
    "    score = pipe.score(X_te, y_te)\n",
    "    y_pred = pipe.predict(X_te)\n",
    "    visualization.visualize_regression_eval(y_te, y_pred, show=False)\n",
    "    print(f\"Fold {fold} R²: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca51f7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from transforms import forest2features\n",
    "\n",
    "# 1) Define transformer wrapping your feature generator\\class Forest2Features(BaseEstimator, TransformerMixin):\n",
    "def __init__(self, population):\n",
    "    self.population = population\n",
    "\n",
    "def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "def transform(self, X):\n",
    "        return forest2features(self.population, X)\n",
    "\n",
    "# 2) Prepare raw data and target\n",
    "#    Assume x_raw is an (N, 4) ndarray and best_forest is defined; column 2 is 'close'\n",
    "raw_prices = x_raw[:, 3]\n",
    "# compute 1-step log-return target of length N-1\n",
    "y_logret = np.log(raw_prices[1:] / raw_prices[:-1])\n",
    "# align features by dropping the last raw row so X_raw_aligned.shape[0] == y_logret.shape[0]\n",
    "X_raw_aligned = x_raw[:-1, :]\n",
    "\n",
    "# 3) Build pipeline\n",
    "pipe = Pipeline([\n",
    "    (\"fe\",     Forest2Features(population=best_forest)),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"lr\",     LinearRegression())\n",
    "])\n",
    "\n",
    "# 4) Time-series cross-validation with post-feature-generation printing\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "for fold, (train_idx, test_idx) in enumerate(tscv.split(X_raw_aligned), start=1):\n",
    "    print(f\"\\n--- Fold {fold} ---\")\n",
    "\n",
    "    # raw train/test splits\n",
    "    X_tr_raw, X_te_raw = X_raw_aligned[train_idx], X_raw_aligned[test_idx]\n",
    "    y_tr,      y_te     = y_logret[train_idx],      y_logret[test_idx]\n",
    "\n",
    "    # generate features using the transformer step\n",
    "    fe = pipe.named_steps['fe']\n",
    "    X_te_feats = fe.transform(X_te_raw)\n",
    "\n",
    "    # inspect the generated features for the test split\n",
    "    print(\"First 3 rows of generated test features:\")\n",
    "    print(X_te_feats[:3])\n",
    "    print(\"Last 3 rows of generated test features:\")\n",
    "    print(X_te_feats[-3:])\n",
    "\n",
    "    # fit the full pipeline (features -> scaler -> model)\n",
    "    pipe.fit(X_tr_raw, y_tr)\n",
    "    score = pipe.score(X_te_raw, y_te)\n",
    "    print(f\"Fold {fold} R²: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44be9aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataext = pd.read_csv(\"../../data/ES15_ext.csv\")\n",
    "x_ext = dataext.values\n",
    "\n",
    "xext_ = transforms.forest2features(\n",
    "    population=best_forest,\n",
    "    x_raw=x_ext\n",
    ")\n",
    "\n",
    "noise = np.random.rand(xext_.shape[0], 1)\n",
    "\n",
    "xext_ = np.hstack([xext_, noise])\n",
    "\n",
    "\n",
    "xext_ = scaler.transform(xext_)\n",
    "\n",
    "ynewe = np.roll(x_ext[:, 3], shift=-1)\n",
    "#np.random.shuffle(ynewe)\n",
    "y_e = np.log(ynewe / x_ext[:, 3])\n",
    "\n",
    "evaluation.standard_LM_evaluation(X_train, xext_, y_train, y_e, model, dirpath, vizout=True, show=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6464006f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for i in range(6,x_raw.shape[0] -1):\n",
    "    x_i = transforms.forest2features(\n",
    "        population=best_forest,\n",
    "        x_raw=x_raw[:i]\n",
    "    )\n",
    "    \n",
    "    x_i[:, 0] = 1\n",
    "\n",
    "    y_i = np.log( x_raw[1:i, 3] / x_raw[:i-1, 3] )\n",
    "    \n",
    "    x_i = np.hstack([x_i, np.random.rand(i, 1)])\n",
    "    x_i = x_i[:-1]\n",
    "    \n",
    "    x_i = scaler.transform(x_i)\n",
    "    \n",
    "    print(model.score(x_i, y_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a0a814",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv(\"../../data/ES15_ext.csv\")\n",
    "xr = x.values\n",
    "\n",
    "x = transforms.forest2features(\n",
    "    population=best_forest,\n",
    "    x_raw=xr\n",
    ")\n",
    "\n",
    "x[:, 0] = 1\n",
    "noise = np.random.rand(x.shape[0], 1)\n",
    "\n",
    "x = np.hstack([x, noise])\n",
    "\n",
    "x = scaler.transform(x)\n",
    "\n",
    "ynewe = np.roll(xr[:, 3], shift=-1)\n",
    "#np.random.shuffle(ynewe)\n",
    "y = (ynewe / xr[:, 3]) - 1\n",
    "\n",
    "pred = model.predict(x)\n",
    "\n",
    "evaluation.standard_LM_evaluation(x, x, y, y, model, dirpath, vizout=True, show=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f677b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.abs(model.predict(X_test)) > 0.0005\n",
    "frac = mask.mean()\n",
    "print(frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52cc8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sign_accuracy_comparative(y_true, y_pred, show=True):\n",
    "    \"\"\"\n",
    "    Plot two accuracy curves versus |y_pred| threshold, starting at 0.00025,\n",
    "    and restrict x-axis to [0, 0.0025].\n",
    "\n",
    "    - 'center': accuracy for predictions with |y_pred| <= threshold\n",
    "    - 'extremes': accuracy for predictions with |y_pred| >= threshold\n",
    "\n",
    "    Args:\n",
    "        y_true: array-like of true values\n",
    "        y_pred: array-like of predicted values\n",
    "        show: whether to display the plot\n",
    "\n",
    "    Returns:\n",
    "        thresholds: filtered array of |y_pred| thresholds (>=0.00025)\n",
    "        center_acc: accuracy for |y_pred| <= threshold\n",
    "        extremes_acc: accuracy for |y_pred| >= threshold\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    abs_pred = np.abs(y_pred)\n",
    "    true_sign = np.sign(y_true)\n",
    "    pred_sign = np.sign(y_pred)\n",
    "\n",
    "    # All unique thresholds, sorted ascending\n",
    "    all_thresholds = np.unique(abs_pred)\n",
    "    all_thresholds.sort()\n",
    "\n",
    "    # Start at a more stable region: ignore thresholds below 0.00025\n",
    "    thresholds = all_thresholds[all_thresholds >= 0.0001]\n",
    "\n",
    "    # Compute accuracies at each filtered threshold\n",
    "    center_acc = np.array([\n",
    "        np.mean(true_sign[abs_pred <= t] == pred_sign[abs_pred <= t])\n",
    "        for t in thresholds\n",
    "    ])\n",
    "    extremes_acc = np.array([\n",
    "        np.mean(true_sign[abs_pred >= t] == pred_sign[abs_pred >= t])\n",
    "        for t in thresholds\n",
    "    ])\n",
    "\n",
    "    if show:\n",
    "        plt.figure()\n",
    "        plt.plot(thresholds, center_acc, marker='o', linestyle='-',\n",
    "                 label='|y_pred| ≤ threshold (center)')\n",
    "        plt.plot(thresholds, extremes_acc, marker='^', linestyle='--',\n",
    "                 label='|y_pred| ≥ threshold (extremes)')\n",
    "        plt.xlabel(\"|y_pred| Threshold\")\n",
    "        plt.ylabel(\"Sign Prediction Accuracy\")\n",
    "        plt.title(\"Accuracy from Center vs. Extremes (from 0.00025)\")\n",
    "        plt.legend()\n",
    "        plt.xlim(0.0001, 0.0025)\n",
    "        plt.show()\n",
    "\n",
    "    return thresholds, center_acc, extremes_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d413c5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model.predict(X_test)\n",
    "sign_accuracy_comparative(y_test, y_pred_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7880bb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sign_accuracy_comparative(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d4b6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in range(1,len(xr)):\n",
    "    p = round(model.predict(x[:i])[-1], 5)\n",
    "    if(abs(p) > 0.0005):\n",
    "        print(f'time: {xr[i, 0]}\\tprice: {xr[i]}\\tpred: {p}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

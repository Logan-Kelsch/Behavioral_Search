{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41c4ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transforms as transforms\n",
    "import population as population\n",
    "import optimize as optimize\n",
    "import utility as utility\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import visualization as visualization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import evaluation as evaluation\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"../../data/ES15.csv\")\n",
    "x_raw = data.values\n",
    "\n",
    "#x_raw, x_ind = train_test_split(x_raw_presplit, test_size=0.1, shuffle=False)\n",
    "\n",
    "dirpath = utility.fetch_new_run_dirpath()\n",
    "\n",
    "\n",
    "\n",
    "pop = population.generate_random_forest(100, 12)\n",
    "\n",
    "np.seterr(all='ignore')\n",
    "best_forest, best_scores, best_overtime = optimize.optimize_constants(\n",
    "    pop, x_raw, sthresh_q=.1, run_dir=dirpath, max_iter=2, vizout=False\n",
    ")\n",
    "\n",
    "img = visualization.visualize_tree(best_forest[best_scores.index(min(best_scores))], run_dir=dirpath, vizout=True)\n",
    "best_forest , best_scores = population.extract_n_best_trees(best_forest, best_scores, -1, run_dir=dirpath, vizout=True)\n",
    "\n",
    "\n",
    "ynew = np.roll(x_raw[:, 3], shift=-1)\n",
    "y_ = np.log(ynew / x_raw[:, 3])\n",
    "#np.random.shuffle(y_)\n",
    "\n",
    "\n",
    "x_ = transforms.forest2features(\n",
    "    population=best_forest,\n",
    "    x_raw=x_raw\n",
    ")\n",
    "\n",
    "#using time column (never utilized) as noise column\n",
    "x_raw[:, 0] = 1\n",
    "noise = np.random.rand(x_raw.shape[0], 1)\n",
    "\n",
    "x_ = np.hstack([x_, noise])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_, y_, test_size=0.3, shuffle=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = evaluation.standard_NN_construction(X_train, y_train, verbose=1)\n",
    "evaluation.standard_LM_evaluation(X_train, X_test, y_train, y_test, model, dirpath, vizout=True, show=True)\n",
    "#evaluation.standard_LM_evaluation(X_train, xind_, y_train, yind_, model, dirpath, vizout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0f5088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transforms as transforms\n",
    "import population as population\n",
    "import optimize as optimize\n",
    "import utility as utility\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import visualization as visualization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import evaluation as evaluation\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"../../data/ES15.csv\")\n",
    "x_raw = data.values\n",
    "\n",
    "#x_raw, x_ind = train_test_split(x_raw_presplit, test_size=0.1, shuffle=False)\n",
    "\n",
    "dirpath = utility.fetch_new_run_dirpath()\n",
    "\n",
    "\n",
    "\n",
    "pop = population.generate_random_forest(200, 12)\n",
    "\n",
    "np.seterr(all='ignore')\n",
    "best_forest, best_scores, best_overtime = optimize.optimize_constants(\n",
    "    pop, x_raw, sthresh_q=.1, run_dir=dirpath, max_iter=-1, vizout=True\n",
    ")\n",
    "\n",
    "img = visualization.visualize_tree(best_forest[best_scores.index(min(best_scores))], run_dir=dirpath, vizout=True)\n",
    "best_forest , best_scores = population.extract_n_best_trees(best_forest, best_scores, 10, run_dir=dirpath, vizout=True)\n",
    "\n",
    "\n",
    "ynew = np.roll(x_raw[:, 3], shift=-1)\n",
    "y_ = np.log(ynew / x_raw[:, 3])\n",
    "#np.random.shuffle(y_)\n",
    "\n",
    "\n",
    "x_ = transforms.forest2features(\n",
    "    population=best_forest,\n",
    "    x_raw=x_raw\n",
    ")\n",
    "\n",
    "\n",
    "#noise = np.random.rand(x_raw.shape[0], 1)\n",
    "#x_ = np.hstack([x_, noise])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_, y_, test_size=0.3, shuffle=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b669a6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "def standard_NN_construction(X_train, y_train, epochs=250, verbose=0):\n",
    "\t\n",
    "\n",
    "\treduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "\t\tmonitor='val_loss',\n",
    "\t\tfactor=0.65, \n",
    "\t\tpatience=3, \n",
    "\t\tmin_lr=1e-6\n",
    "\t)\n",
    "\tearly_stopping = EarlyStopping(monitor='loss', patience=25, mode='min', restore_best_weights=True)\n",
    "\n",
    "\topt  = tf.keras.optimizers.Adam()\n",
    "\topt2 = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "\tdef build_model():\n",
    "\t\tmodel = tf.keras.Sequential([\n",
    "\t\t\ttf.keras.layers.Input(shape=(X_train.shape[1],)),\n",
    "\t\t\ttf.keras.layers.Dense(64, activation='relu'),\n",
    "\t\t\ttf.keras.layers.BatchNormalization(),\n",
    "\t\t\ttf.keras.layers.Dense(64, activation='relu'),  \n",
    "\t\t\ttf.keras.layers.Dropout(0.2),\n",
    "\t\t\ttf.keras.layers.Dense(64, activation='relu'),       \n",
    "\t\t\ttf.keras.layers.Dense(1, activation='linear')  # Output layer for regression\n",
    "\t\t])\n",
    "\t\t\n",
    "\t\trmse='root_mean_squared_error'\n",
    "\n",
    "\t\tmodel.compile(optimizer=opt2, loss='mse', metrics=['R2Score'])\n",
    "\t\treturn model\n",
    "\n",
    "\twith tf.device('/GPU:0'):\n",
    "\t\tmodel = build_model()\n",
    "\t\thistory = model.fit(X_train, y_train, epochs=epochs, batch_size=512, \\\n",
    "\t\t\t\t\t\tvalidation_split=0.2, verbose=verbose, shuffle=True, callbacks=[reduce_lr, early_stopping])\n",
    "\t\t\n",
    "\treturn model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4f9391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import reproduction\n",
    "best_forest = reproduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca194cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transforms, evaluation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv(\"../../data/ES15.csv\")\n",
    "x_raw = data.values\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ynew = np.roll(x_raw[:, 3], shift=-1)\n",
    "y_ = np.log(ynew / x_raw[:, 3])\n",
    "#np.random.shuffle(y_)\n",
    "\n",
    "import serialization\n",
    "\n",
    "best_forest = serialization.load_forest(where='../../runs/run_5/best.4st')\n",
    "\n",
    "x_ = transforms.forest2features(\n",
    "    population=best_forest,\n",
    "    x_raw=x_raw\n",
    ")\n",
    "\n",
    "\n",
    "#noise = np.random.rand(x_raw.shape[0], 1)\n",
    "#x_ = np.hstack([x_, noise])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_, y_, test_size=0.3, shuffle=True, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56315764",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = evaluation.standard_LM_construction(X_train, y_train)\n",
    "evaluation.standard_LM_evaluation(X_train, X_test, y_train, y_test, model, '', vizout=False, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a9b614",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history = evaluation.standard_NN_construction(X_train, y_train, epochs=50, verbose=1)\n",
    "evaluation.standard_NN_evaluation(X_train, X_test, y_train, y_test, model, history, run_dir='', vizout=False, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068de9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8e31a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import serialization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path, scores = serialization.load_deeplist(where='../../runs/run_25/path_pscr.hstry')\n",
    "\n",
    "plt.plot(range(len(scores)), scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e344ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../../data/ES15.csv\")\n",
    "x_raw = data.values\n",
    "best_forest = serialization.load_forest(where='../../runs/run_49/best.4st')\n",
    "import optimize\n",
    "x_ = transforms.forest2features(\n",
    "\tpopulation=best_forest,\n",
    "\tx_raw=x_raw\n",
    ")\n",
    "_, __, best_scores = evaluation.evaluate_forest_newer(x_, close_prices=x_raw[:, 3], lag_range=(1, 3))\n",
    "loss = optimize.loss_fc(best_scores)\n",
    "print(loss)\n",
    "\n",
    "for i in range(len(best_forest)):\n",
    "\tprint(transforms.get_oplist(best_forest[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0130c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# label train‐vs‐test rows\n",
    "X_tv = np.vstack([X_train, X_test])\n",
    "y_tv = np.array([0]*len(X_train) + [1]*len(X_test))\n",
    "adv = LogisticRegression().fit(X_tv, y_tv)\n",
    "print(\"AUC distinguishing train vs test:\", adv.score(X_tv, y_tv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a61505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from transforms import forest2features\n",
    "\n",
    "# 1) Define the transformer that wraps your feature generator\n",
    "class Forest2Features(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, population):\n",
    "        self.population = population\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # X is your raw x_raw array (n_samples, 4)\n",
    "        return forest2features(self.population, X)\n",
    "\n",
    "# 2) Prepare your raw data and target\n",
    "#    Assume x_raw is an (N, 4) ndarray and best_forest is defined\n",
    "#    Column 2 is the 'close' price\n",
    "raw_prices = x_raw[:, 3]\n",
    "# compute 1-step log-return target of length N-1\n",
    "y_logret = np.log(raw_prices[1:] / raw_prices[:-1])\n",
    "# align features by dropping the last raw row so X_raw_aligned.shape[0] == y_logret.shape[0]\n",
    "X_raw_aligned = x_raw[:-1, :]\n",
    "\n",
    "noise = np.random.rand(X_raw_aligned.shape[0], 1)\n",
    "\n",
    "X_raw_aligned = np.hstack([X_raw_aligned, noise])\n",
    "\n",
    "# 3) Build the pipeline\n",
    "pipe = Pipeline([\n",
    "    (\"fe\",     Forest2Features(population=best_forest)),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"lr\",     LinearRegression())\n",
    "])\n",
    "\n",
    "# 4) Time-series cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "for fold, (train_idx, test_idx) in enumerate(tscv.split(X_raw_aligned), 1):\n",
    "    X_tr, X_te = X_raw_aligned[train_idx], X_raw_aligned[test_idx]\n",
    "    y_tr, y_te = y_logret     [train_idx], y_logret     [test_idx]\n",
    "\n",
    "    #y_tr = np.random.permutation(y_tr)\n",
    "\n",
    "    pipe.fit(X_tr, y_tr)\n",
    "    \n",
    "    perm = permutation_importance(pipe,\n",
    "                              X_tr, y_tr,\n",
    "                              n_repeats=5,\n",
    "                              random_state=0,\n",
    "                              scoring='r2')\n",
    "    perm_importances = pd.Series(perm.importances_mean)\n",
    "    print(perm_importances)\n",
    "\t#print(\"impt: \",perm_importances.max(),perm_importances[4])\n",
    "\n",
    "    score = pipe.score(X_te, y_te)\n",
    "    y_pred = pipe.predict(X_te)\n",
    "    visualization.visualize_regression_eval(y_te, y_pred, show=False)\n",
    "    print(f\"Fold {fold} R²: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca51f7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from transforms import forest2features\n",
    "\n",
    "# 1) Define transformer wrapping your feature generator\\class Forest2Features(BaseEstimator, TransformerMixin):\n",
    "def __init__(self, population):\n",
    "    self.population = population\n",
    "\n",
    "def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "def transform(self, X):\n",
    "        return forest2features(self.population, X)\n",
    "\n",
    "# 2) Prepare raw data and target\n",
    "#    Assume x_raw is an (N, 4) ndarray and best_forest is defined; column 2 is 'close'\n",
    "raw_prices = x_raw[:, 3]\n",
    "# compute 1-step log-return target of length N-1\n",
    "y_logret = np.log(raw_prices[1:] / raw_prices[:-1])\n",
    "# align features by dropping the last raw row so X_raw_aligned.shape[0] == y_logret.shape[0]\n",
    "X_raw_aligned = x_raw[:-1, :]\n",
    "\n",
    "# 3) Build pipeline\n",
    "pipe = Pipeline([\n",
    "    (\"fe\",     Forest2Features(population=best_forest)),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"lr\",     LinearRegression())\n",
    "])\n",
    "\n",
    "# 4) Time-series cross-validation with post-feature-generation printing\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "for fold, (train_idx, test_idx) in enumerate(tscv.split(X_raw_aligned), start=1):\n",
    "    print(f\"\\n--- Fold {fold} ---\")\n",
    "\n",
    "    # raw train/test splits\n",
    "    X_tr_raw, X_te_raw = X_raw_aligned[train_idx], X_raw_aligned[test_idx]\n",
    "    y_tr,      y_te     = y_logret[train_idx],      y_logret[test_idx]\n",
    "\n",
    "    # generate features using the transformer step\n",
    "    fe = pipe.named_steps['fe']\n",
    "    X_te_feats = fe.transform(X_te_raw)\n",
    "\n",
    "    # inspect the generated features for the test split\n",
    "    print(\"First 3 rows of generated test features:\")\n",
    "    print(X_te_feats[:3])\n",
    "    print(\"Last 3 rows of generated test features:\")\n",
    "    print(X_te_feats[-3:])\n",
    "\n",
    "    # fit the full pipeline (features -> scaler -> model)\n",
    "    pipe.fit(X_tr_raw, y_tr)\n",
    "    score = pipe.score(X_te_raw, y_te)\n",
    "    print(f\"Fold {fold} R²: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44be9aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataext = pd.read_csv(\"../../data/ES15_ext.csv\")\n",
    "x_ext = dataext.values\n",
    "\n",
    "xext_ = transforms.forest2features(\n",
    "    population=best_forest,\n",
    "    x_raw=x_ext\n",
    ")\n",
    "\n",
    "noise = np.random.rand(xext_.shape[0], 1)\n",
    "\n",
    "xext_ = np.hstack([xext_, noise])\n",
    "\n",
    "\n",
    "xext_ = scaler.transform(xext_)\n",
    "\n",
    "ynewe = np.roll(x_ext[:, 3], shift=-1)\n",
    "#np.random.shuffle(ynewe)\n",
    "y_e = np.log(ynewe / x_ext[:, 3])\n",
    "\n",
    "evaluation.standard_LM_evaluation(X_train, xext_, y_train, y_e, model, dirpath, vizout=True, show=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6464006f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for i in range(6,x_raw.shape[0] -1):\n",
    "    x_i = transforms.forest2features(\n",
    "    \tpopulation=best_forest,\n",
    "    \tx_raw=x_raw[:i]\n",
    "\t)\n",
    "    \n",
    "    x_i[:, 0] = 1\n",
    "\n",
    "    y_i = np.log( x_raw[1:i, 3] / x_raw[:i-1, 3] )\n",
    "    \n",
    "    x_i = np.hstack([x_i, np.random.rand(i, 1)])\n",
    "    x_i = x_i[:-1]\n",
    "    \n",
    "    x_i = scaler.transform(x_i)\n",
    "    \n",
    "    print(model.score(x_i, y_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a0a814",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv(\"../../data/ES15_ext.csv\")\n",
    "xr = x.values\n",
    "\n",
    "x = transforms.forest2features(\n",
    "    population=best_forest,\n",
    "\tx_raw=xr\n",
    ")\n",
    "\n",
    "x[:, 0] = 1\n",
    "noise = np.random.rand(x.shape[0], 1)\n",
    "\n",
    "x = np.hstack([x, noise])\n",
    "\n",
    "x = scaler.transform(x)\n",
    "\n",
    "ynewe = np.roll(xr[:, 3], shift=-1)\n",
    "#np.random.shuffle(ynewe)\n",
    "y = (ynewe / xr[:, 3]) - 1\n",
    "\n",
    "pred = model.predict(x)\n",
    "\n",
    "evaluation.standard_LM_evaluation(x, x, y, y, model, dirpath, vizout=True, show=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f677b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.abs(model.predict(X_test)) > 0.0005\n",
    "frac = mask.mean()\n",
    "print(frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52cc8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sign_accuracy_comparative(y_true, y_pred, show=True):\n",
    "    \"\"\"\n",
    "    Plot two accuracy curves versus |y_pred| threshold, starting at 0.00025,\n",
    "    and restrict x-axis to [0, 0.0025].\n",
    "\n",
    "    - 'center': accuracy for predictions with |y_pred| <= threshold\n",
    "    - 'extremes': accuracy for predictions with |y_pred| >= threshold\n",
    "\n",
    "    Args:\n",
    "        y_true: array-like of true values\n",
    "        y_pred: array-like of predicted values\n",
    "        show: whether to display the plot\n",
    "\n",
    "    Returns:\n",
    "        thresholds: filtered array of |y_pred| thresholds (>=0.00025)\n",
    "        center_acc: accuracy for |y_pred| <= threshold\n",
    "        extremes_acc: accuracy for |y_pred| >= threshold\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    abs_pred = np.abs(y_pred)\n",
    "    true_sign = np.sign(y_true)\n",
    "    pred_sign = np.sign(y_pred)\n",
    "\n",
    "    # All unique thresholds, sorted ascending\n",
    "    all_thresholds = np.unique(abs_pred)\n",
    "    all_thresholds.sort()\n",
    "\n",
    "    # Start at a more stable region: ignore thresholds below 0.00025\n",
    "    thresholds = all_thresholds[all_thresholds >= 0.0001]\n",
    "\n",
    "    # Compute accuracies at each filtered threshold\n",
    "    center_acc = np.array([\n",
    "        np.mean(true_sign[abs_pred <= t] == pred_sign[abs_pred <= t])\n",
    "        for t in thresholds\n",
    "    ])\n",
    "    extremes_acc = np.array([\n",
    "        np.mean(true_sign[abs_pred >= t] == pred_sign[abs_pred >= t])\n",
    "        for t in thresholds\n",
    "    ])\n",
    "\n",
    "    if show:\n",
    "        plt.figure()\n",
    "        plt.plot(thresholds, center_acc, marker='o', linestyle='-',\n",
    "                 label='|y_pred| ≤ threshold (center)')\n",
    "        plt.plot(thresholds, extremes_acc, marker='^', linestyle='--',\n",
    "                 label='|y_pred| ≥ threshold (extremes)')\n",
    "        plt.xlabel(\"|y_pred| Threshold\")\n",
    "        plt.ylabel(\"Sign Prediction Accuracy\")\n",
    "        plt.title(\"Accuracy from Center vs. Extremes (from 0.00025)\")\n",
    "        plt.legend()\n",
    "        plt.xlim(0.0001, 0.0025)\n",
    "        plt.show()\n",
    "\n",
    "    return thresholds, center_acc, extremes_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d413c5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model.predict(X_test)\n",
    "sign_accuracy_comparative(y_test, y_pred_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7880bb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sign_accuracy_comparative(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d4b6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in range(1,len(xr)):\n",
    "    p = round(model.predict(x[:i])[-1], 5)\n",
    "    if(abs(p) > 0.0005):\n",
    "\t    print(f'time: {xr[i, 0]}\\tprice: {xr[i]}\\tpred: {p}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
